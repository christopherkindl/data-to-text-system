{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from Model import BERTRanker\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "from parser import Parser, recursion, program_eq, split_prog\n",
    "from collections import Counter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm, trange\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime \n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "from transformers import (WEIGHTS_NAME, AdamW, BertConfig, BertTokenizer, \n",
    "                        BertModel, get_linear_schedule_with_warmup, \n",
    "                        squad_convert_examples_to_features)\n",
    "from APIs import all_funcs\n",
    "\n",
    "device = torch.device('cuda')\n",
    "MODEL_CLASSES = {\"bert\": (BertConfig, BertModel, BertTokenizer)}\n",
    "\n",
    "class ParseNLIDataset(Dataset):\n",
    "    def __init__(self, bootstrap_data, weakly_data, tokenizer):\n",
    "        self.bootstrap_data = bootstrap_data\n",
    "        self.weakly_data = weakly_data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        #self.sent_max_len = 80\n",
    "        self.max_len = 120\n",
    "\n",
    "    @classmethod\n",
    "    def convert(cls, sent, prog, title, tokenizer, max_len):\n",
    "        title = '[CLS] title : {} [SEP]'.format(title)\n",
    "        title_ids = tokenizer.encode(title, add_special_tokens=False)\n",
    "        types = [1] * len(title_ids)\n",
    "\n",
    "        sent = '{} [SEP]'.format(sent)\n",
    "        sent_ids = tokenizer.encode(sent, add_special_tokens=False)\n",
    "        types += [0] * len(sent_ids)\n",
    "\n",
    "        prog = '{} [SEP]'.format(prog)\n",
    "        prog_ids = tokenizer.encode(prog, add_special_tokens=False)\n",
    "        types += [1] * len(prog_ids)\n",
    "\n",
    "        token_ids = title_ids + sent_ids + prog_ids\n",
    "\n",
    "        if len(types) > max_len:\n",
    "            token_ids = token_ids[:max_len]\n",
    "            masks = [1] * max_len            \n",
    "            types = types[:max_len]\n",
    "        else:\n",
    "            token_ids = token_ids + [tokenizer.pad_token_id] * (max_len - len(types))\n",
    "            masks = [1] * len(types) + [0] * (max_len - len(types))            \n",
    "            types = types + [0] * (max_len - len(types))\n",
    "\n",
    "        return token_ids, masks, types\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if random.random() < 0.4:\n",
    "            entry = random.choice(self.bootstrap_data)\n",
    "        else:\n",
    "            entry = random.choice(self.weakly_data)\n",
    "        #entry = random.choice(self.weakly_data)\n",
    "\n",
    "        sent = entry[0]\n",
    "        prog = entry[1]\n",
    "        title = entry[2]\n",
    "        label = entry[3]\n",
    "\n",
    "        token_ids, masks, types = self.convert(sent, prog, title, self.tokenizer, self.max_len)\n",
    "\n",
    "        token_ids = np.array(token_ids, 'int64')\n",
    "        types = np.array(types, 'int64')\n",
    "        masks = np.array(masks, 'int64')\n",
    "        label = np.array(label, 'int64')\n",
    "\n",
    "        return token_ids, types, masks, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.bootstrap_data) + len(self.weakly_data)\n",
    "        #return len(self.weakly_data)\n",
    "\n",
    "def get_model(model_type, model_name_or_path, cache_dir):\n",
    "    config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "    config = config_class.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        cache_dir=cache_dir,\n",
    "    )\n",
    "    tokenizer = tokenizer_class.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        do_lower_case=True,\n",
    "        cache_dir=cache_dir,\n",
    "    )\n",
    "    tokenizer.add_tokens([\"[{}]\".format(_) for _ in all_funcs])\n",
    "    tokenizer.add_tokens([\"all_rows\"])\n",
    "    model = BERTRanker(model_class, model_name_or_path, config, cache_dir)\n",
    "    model.base.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "def convert_program(program):\n",
    "    arrays, _ = split_prog(program, True)\n",
    "    for i in range(len(arrays) - 1):\n",
    "        if arrays[i + 1] == '{':\n",
    "            arrays[i] = '[{}]'.format(arrays[i])\n",
    "    return \" \".join(arrays)\n",
    "\n",
    "def evaluate(tokenizer, model, parser):\n",
    "    with open('data/test_lm_pos_neg.json') as f:\n",
    "        data = json.load(f)\n",
    "    data = dict(list(data.items())[:200])\n",
    "\n",
    "    positive_sents = []\n",
    "    negative_sents = []\n",
    "    table_names = []\n",
    "    for k, vs in data.items():\n",
    "        for v in vs:\n",
    "            positive_sents.append(v['pos'][0])\n",
    "            negative_sents.append(v['neg'][0])\n",
    "            table_names.append(k)\n",
    "\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    print(\"Using {} cores to run on {} instances\".format(cores, len(positive_sents)))\n",
    "    pool = Pool(cores)\n",
    "    pos_res = pool.map(parser.distribute_parse, zip(table_names, positive_sents))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    print(\"Using {} cores to run on {} instances\".format(cores, len(negative_sents)))\n",
    "    pool = Pool(cores)\n",
    "    neg_res = pool.map(parser.distribute_parse, zip(table_names, negative_sents))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    model.eval()\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for res, polarity in zip([pos_res, neg_res], [True, False]):\n",
    "        for sent, programs, title in res:\n",
    "            labels = []\n",
    "            token_ids = []\n",
    "            types = []\n",
    "            masks = []\n",
    "            \n",
    "            if len(programs) > 0:\n",
    "                for prog in programs[:64]:\n",
    "                    token_id, type_, mask = ParseNLIDataset.convert(sent, convert_program(prog), title, tokenizer, 120)\n",
    "                    token_ids.append(token_id)\n",
    "                    types.append(type_)\n",
    "                    masks.append(mask)\n",
    "                    labels.append('=True' in prog)\n",
    "\n",
    "                token_ids = torch.LongTensor(token_ids).to(device)\n",
    "                types = torch.LongTensor(types).to(device)\n",
    "                masks = torch.LongTensor(masks).to(device)\n",
    "                \n",
    "                probs = model.prob(token_ids, types, masks)\n",
    "                pred = labels[torch.argmax(probs, 0).item()]\n",
    "            else:\n",
    "                pred = False\n",
    "\n",
    "            if pred and polarity:\n",
    "                tp += 1\n",
    "            elif pred and not polarity:\n",
    "                fp += 1\n",
    "            elif not pred and polarity:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "\n",
    "            sys.stdout.write(\"TP={},TN={},FP={},FN={},ACC={} \\r\".format(tp, tn, fp, fn, (tp + tn)/(tp + tn + fp + fn)))\n",
    "\n",
    "    accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    print(\"TP={},TN={},FP={},FN={},ACC={}\".format(tp, tn, fp, fn, accuracy))\n",
    "    model.train()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--gen_prog\", default=False, action=\"store_true\", help=\"whether to generate programs\")\n",
    "    parser.add_argument(\"--rank_prog_bert\", default=False, action=\"store_true\", help=\"whether to rank programs\")\n",
    "    parser.add_argument(\"--parse\", default=False, action=\"store_true\", help=\"whether to parse the output file\")\n",
    "    parser.add_argument(\"--compute_score\", default=False, action=\"store_true\", help=\"whether to compute SP-Acc score\")\n",
    "    parser.add_argument(\"--score_file\", default=None, type=str, help=\"The input file to be scored\")\n",
    "    parser.add_argument(\"--batch_size\", default=64, type=int, help=\"batch size for training\")\n",
    "    parser.add_argument(\"--model_type\", default='bert', type=str, help=\"the model type\")\n",
    "    parser.add_argument(\"--preprocess\", default=False, action=\"store_true\", help=\"whether to rank programs\")\n",
    "    parser.add_argument(\"--model_name_or_path\", default='bert-base-uncased', type=str, help=\"batch size for training\")    \n",
    "    parser.add_argument(\"--num_workers\", default=16, type=int, help=\"number of workers in the dataloader\")\n",
    "    parser.add_argument(\"--load_from\", default=None, type=str, help=\"which model to load from\")\n",
    "    parser.add_argument(\"--csv_path\", default='data/all_csv', type=str, help=\"all_csv path\")\n",
    "    parser.add_argument(\"--cache_dir\", default='/tmp/', type=str, help=\"where to cache the BERT model\")\n",
    "    parser.add_argument(\"--learning_rate\", default=1e-5, type=float, help=\"The initial learning rate for Adam.\")        \n",
    "    parser.add_argument(\"--num_train_epochs\", default=10, type=int, help=\"Total number of training epochs to perform.\")\n",
    "    parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=1,\n",
    "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    "    )\n",
    "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
    "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
    "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
    "    parser.add_argument(\"--logging_steps\", default=50, type=int, help=\"Epsilon for Adam optimizer.\")    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.gen_prog:\n",
    "        model = Parser(args.csv_path)\n",
    "        with open('data/bootstrap.json') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        indexing = []\n",
    "        table_names = []\n",
    "        titles = []\n",
    "        sents = []\n",
    "        parses = []\n",
    "        for k, vs in data.items():\n",
    "            for v in vs:\n",
    "                indexing.append(len(table_names))\n",
    "                table_names.append(k)\n",
    "                titles.append(v[2])\n",
    "                sents.append(v[0])\n",
    "                parses.append(v[-1])\n",
    "\n",
    "\n",
    "        def func(inputs):\n",
    "            index, table_name, title, sent, parse = inputs\n",
    "            \n",
    "            if os.path.exists('data/bootstrap_programs/{}/{}'.format('fail', table_name)) or\\\n",
    "                os.path.exists('data/bootstrap_programs/{}/{}'.format('success', table_name)):\n",
    "                return\n",
    "            else:\n",
    "                rs, masked_sent, mapping = model.parse(table_name, sent)\n",
    "                result = 'fail'\n",
    "                for r in rs:\n",
    "                    if program_eq(r, parse):\n",
    "                        result = 'success'\n",
    "                        break\n",
    "                output_file = 'data/bootstrap_programs/{}/{}'.format(result, table_name)\n",
    "\n",
    "                with open(output_file, 'w') as f:\n",
    "                    json.dump((table_name, sent, title, rs, parse, masked_sent, mapping), f, indent=2)\n",
    "\n",
    "        cores = multiprocessing.cpu_count()\n",
    "        print(\"Using {} cores for {} instances\".format(cores, len(sents)))\n",
    "        pool = Pool(cores)\n",
    "        res = pool.map(func, zip(indexing, table_names, titles, sents, parses))\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        model = Parser(args.csv_path)\n",
    "\n",
    "        with open('data/train_lm.json') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        indexing = []\n",
    "        table_names = []\n",
    "        titles = []\n",
    "        sents = []\n",
    "        for k, vs in data.items():\n",
    "            for v in vs:\n",
    "                indexing.append(len(table_names))\n",
    "                table_names.append(k)\n",
    "                titles.append(v[2])\n",
    "                sents.append(v[0])\n",
    "\n",
    "        def func(inputs):\n",
    "            index, table_name, title, sent = inputs\n",
    "            output_file = 'data/all_programs/{}_program.json'.format(index)\n",
    "            if not os.path.exists(output_file):\n",
    "                rs, masked_sent, mapping = model.parse(table_name, sent)\n",
    "                with open(output_file, 'w') as f:\n",
    "                    json.dump((table_name, sent, title, rs, None, masked_sent, mapping), f, indent=2)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        cores = multiprocessing.cpu_count()\n",
    "        print(\"Using {} cores for {} instances\".format(cores, len(sents)))\n",
    "        pool = Pool(cores)\n",
    "        res = pool.map(func, zip(indexing, table_names, titles, sents))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        with open('data/train_adv_lm.json') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        indexing = []\n",
    "        table_names = []\n",
    "        titles = []\n",
    "        sents = []\n",
    "        for k, vs in data.items():\n",
    "            for v in vs:\n",
    "                indexing.append(len(table_names))\n",
    "                table_names.append(k)\n",
    "                titles.append(v[2])\n",
    "                sents.append(v[0])\n",
    "\n",
    "        def func(inputs):\n",
    "            index, table_name, title, sent = inputs\n",
    "            output_file = 'data/all_adv_programs/{}_program.json'.format(index)\n",
    "            if not os.path.exists(output_file):\n",
    "                rs, masked_sent, mapping = model.parse(table_name, sent)\n",
    "                with open(output_file, 'w') as f:\n",
    "                    json.dump((table_name, sent, title, rs, None, masked_sent, mapping), f, indent=2)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        cores = multiprocessing.cpu_count()\n",
    "        print(\"Using {} cores for {} instances\".format(cores, len(sents)))\n",
    "        pool = Pool(cores)\n",
    "        res = pool.map(func, zip(indexing, table_names, titles, sents))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    if args.rank_prog_bert:\n",
    "        if not os.path.exists('data/training_data_for_ranker.json'):\n",
    "            bootstrap_results = []\n",
    "            for d in os.listdir('data/bootstrap_programs/success/'):\n",
    "                if d.endswith('.csv'):\n",
    "                    with open('data/bootstrap_programs/success/{}'.format(d), 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    gt_program = data[-3]\n",
    "                    mapping = data[-1]\n",
    "                    imapping = {v:k for k, v in mapping.items()}\n",
    "                    for prog in data[3]:\n",
    "                        if program_eq(prog, gt_program):\n",
    "                            label = 1\n",
    "                        else:\n",
    "                            label = 0\n",
    "                        # split program\n",
    "                        bootstrap_results.append((data[1], convert_program(prog), data[2], label))\n",
    "\n",
    "            print(\"done constructing the bootstrap postive and negative samples\")\n",
    "            \n",
    "            # Constructing the bootstrap instances        \n",
    "            weakly_results = []\n",
    "            for d in os.listdir('data/all_programs/'):\n",
    "                if d.endswith('.json'):\n",
    "                    with open('data/all_programs/{}'.format(d), 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    mapping = data[-1]\n",
    "                    imapping = {v:k for k, v in mapping.items()}\n",
    "                    for prog in data[3]:\n",
    "                        if '=True' in prog:\n",
    "                            label = 1\n",
    "                        elif '=False':\n",
    "                            label = 0\n",
    "                        else:\n",
    "                            raise NotImplementedError\n",
    "                        weakly_results.append((data[1], convert_program(prog), data[2], label))\n",
    "\n",
    "            for d in os.listdir('data/all_adv_programs/'):\n",
    "                if d.endswith('.json'):\n",
    "                    with open('data/all_adv_programs/{}'.format(d), 'r') as f:\n",
    "                        data = json.load(f)\n",
    "                    \n",
    "                    mapping = data[-1]\n",
    "                    imapping = {v:k for k, v in mapping.items()}\n",
    "                    for prog in data[3]:\n",
    "                        if '=True' in prog:\n",
    "                            label = 0\n",
    "                        elif '=False':\n",
    "                            label = 1\n",
    "                        else:\n",
    "                            raise NotImplementedError\n",
    "                        weakly_results.append((data[1], convert_program(prog), data[2], label))\n",
    "\n",
    "            print(\"done constructing the weakly postive and negative samples\")\n",
    "\n",
    "            with open('data/training_data_for_ranker.json', 'w') as f:\n",
    "                json.dump({'bootstrap': bootstrap_results, 'weakly': weakly_results}, f, indent=2)\n",
    "        else:\n",
    "            with open('data/training_data_for_ranker.json', 'r') as f:\n",
    "                data = json.load(f)\n",
    "            bootstrap_results = data['bootstrap']\n",
    "            weakly_results = data['weakly']\n",
    "\n",
    "        tokenizer, model = get_model(args.model_type, args.model_name_or_path, args.cache_dir)\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        dataset = ParseNLIDataset(bootstrap_results, weakly_results, tokenizer)\n",
    "\n",
    "        train_dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": args.weight_decay,\n",
    "            },\n",
    "            {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "        ]\n",
    "\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "\n",
    "        recording_time = datetime.now().strftime('%m_%d_%H_%M')\n",
    "        tb_writer = SummaryWriter(log_dir='tmp/{}'.format(recording_time))\n",
    "        \n",
    "        global_step = 0\n",
    "        tr_loss = 0\n",
    "        parser = Parser(args.csv_path)\n",
    "\n",
    "        evaluate_every = int(len(train_dataloader) / 10)\n",
    "        print(\"evaluating the model every {} steps\".format(evaluate_every))\n",
    "        for epoch in trange(0, 10, desc='Epoch'):\n",
    "            for i, batch in enumerate(tqdm(train_dataloader, 'Iteration')):\n",
    "                batch = tuple(Variable(t).to(device) for t in batch)\n",
    "\n",
    "                token_ids, types, masks, label = batch\n",
    "\n",
    "                model.zero_grad()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                logits = model(token_ids, types, masks)\n",
    "\n",
    "                loss = criterion(logits, label)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate schedule\n",
    "\n",
    "                global_step += 1\n",
    "                tr_loss += loss.item()\n",
    "\n",
    "                if global_step % args.logging_steps == 0:\n",
    "                    tb_writer.add_scalar(\"loss\", tr_loss / args.logging_steps, global_step)\n",
    "                    tr_loss = 0\n",
    "\n",
    "                if i % evaluate_every == 0 and i > 0:\n",
    "                    acc = format(evaluate(tokenizer, model, parser), '.2f')\n",
    "                    torch.save(model.state_dict(), 'parser_models/parser_step{}_acc{}.pt'.format(global_step, acc))      \n",
    "        \n",
    "        tb_writer.close()\n",
    "\n",
    "    if args.parse:\n",
    "        with open(args.score_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        parser = Parser(args.csv_path)\n",
    "        table_names = []\n",
    "        sents = []\n",
    "        for k, vs in data.items():\n",
    "            for v in vs:\n",
    "                table_names.append(k)\n",
    "                sents.append(v)\n",
    "        \n",
    "        cores = multiprocessing.cpu_count()\n",
    "        print(\"Using {} cores to run on {} instances\".format(cores, len(sents)))\n",
    "        pool = Pool(cores)\n",
    "        results = pool.map(parser.distribute_parse, zip(table_names, sents))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        with open(\"program_{}\".format(args.score_file), 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "    if args.compute_score:\n",
    "        tokenizer, model = get_model(args.model_type, args.model_name_or_path, args.cache_dir)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        model.load_state_dict(torch.load(args.load_from))\n",
    "\n",
    "        with open(args.score_file, 'r') as f:\n",
    "            results = json.load(f)\n",
    "\n",
    "        succ, total = 0, 0\n",
    "        for sent, programs, title in results:\n",
    "            labels = []\n",
    "            token_ids = []\n",
    "            types = []\n",
    "            masks = []\n",
    "            \n",
    "            if len(programs) > 0:\n",
    "                for prog in programs[:36]:\n",
    "                    token_id, type_, mask = ParseNLIDataset.convert(sent, convert_program(prog), title, tokenizer, 120)\n",
    "                    token_ids.append(token_id)\n",
    "                    types.append(type_)\n",
    "                    masks.append(mask)\n",
    "                    labels.append(1 if '=True' in prog else 0)\n",
    "\n",
    "                token_ids = torch.LongTensor(token_ids).to(device)\n",
    "                types = torch.LongTensor(types).to(device)\n",
    "                masks = torch.LongTensor(masks).to(device)\n",
    "                \n",
    "                probs = model.prob(token_ids, types, masks)\n",
    "                if len(labels) > 8:\n",
    "                    tmp = []\n",
    "                    for _ in probs.topk(3)[1].tolist():\n",
    "                        tmp.append(labels[_])\n",
    "                    if sum(tmp) > 0:\n",
    "                        pred = 1\n",
    "                    else:\n",
    "                        pred = 0\n",
    "                else:\n",
    "                    pred = labels[torch.argmax(probs, 0).item()]\n",
    "            else:\n",
    "                pred = 0\n",
    "            \n",
    "            if pred:\n",
    "                succ += 1\n",
    "            total += 1\n",
    "            sys.stdout.write('accuracy = {} \\r'.format(succ / total))\n",
    "\n",
    "        print(\"accuracy = {}\".format(succ / total))\n",
    "\n",
    "\n",
    "    if args.preprocess:\n",
    "        with open('data/test_lm.json') as f:\n",
    "            data = json.load(f)\n",
    "        data = dict(list(data.items())[:30])\n",
    "\n",
    "        # refers to the path all_data/csv \n",
    "        parser = Parser(args.csv_path)\n",
    "        positive_sents = []\n",
    "        table_names = []\n",
    "        for k, vs in data.items():\n",
    "            for v in vs:\n",
    "                print('About to print v:')\n",
    "                print(v)\n",
    "                positive_sents.append(v[0])\n",
    "                table_names.append(k)\n",
    "\n",
    "        for _ in zip(table_names, positive_sents):\n",
    "            print(parser.preprocess(_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
